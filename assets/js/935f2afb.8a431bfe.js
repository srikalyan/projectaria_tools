"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8581],{13229:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Project Aria Tools","href":"/projectaria_tools/docs/intro","docId":"intro"},{"type":"category","label":"Technical Specifications","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Hardware Specifications","href":"/projectaria_tools/docs/tech_spec/hardware_spec","docId":"tech_spec/hardware_spec"},{"type":"link","label":"Recording Profiles","href":"/projectaria_tools/docs/tech_spec/recording_profiles","docId":"tech_spec/recording_profiles"},{"type":"link","label":"Device Calibration","href":"/projectaria_tools/docs/tech_spec/device_calibration","docId":"tech_spec/device_calibration"}],"href":"/projectaria_tools/docs/tech_spec/"},{"type":"category","label":"Data Formats","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Aria VRS","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Format","href":"/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs_format","docId":"data_formats/aria_vrs/aria_vrs_format"},{"type":"link","label":"Timestamp Definitions","href":"/projectaria_tools/docs/data_formats/aria_vrs/timestamps_in_aria_vrs","docId":"data_formats/aria_vrs/timestamps_in_aria_vrs"}],"href":"/projectaria_tools/docs/data_formats/aria_vrs/"},{"type":"category","label":"MPS Outputs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Basics","href":"/projectaria_tools/docs/data_formats/mps/mps_summary","docId":"data_formats/mps/mps_summary"},{"type":"category","label":"SLAM","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Trajectory","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_trajectory","docId":"data_formats/mps/slam/mps_trajectory"},{"type":"link","label":"Semi-Dense Point Cloud","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_pointcloud","docId":"data_formats/mps/slam/mps_pointcloud"},{"type":"link","label":"Calibration Data","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_calibration","docId":"data_formats/mps/slam/mps_calibration"},{"type":"link","label":"Multi-SLAM","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam","docId":"data_formats/mps/slam/mps_multi_slam"}],"href":"/projectaria_tools/docs/data_formats/mps/slam/"},{"type":"link","label":"Eye Gaze","href":"/projectaria_tools/docs/data_formats/mps/mps_eye_gaze","docId":"data_formats/mps/mps_eye_gaze"}]},{"type":"category","label":"Coordinate Conventions","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"2D Image Coordinate System Conventions","href":"/projectaria_tools/docs/data_formats/coordinate_convention/2d_image_coordinate_system_convention","docId":"data_formats/coordinate_convention/2d_image_coordinate_system_convention"},{"type":"link","label":"3D Coordinate Frame Conventions","href":"/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention","docId":"data_formats/coordinate_convention/3d_coordinate_frame_convention"}]}],"href":"/projectaria_tools/docs/data_formats/"},{"type":"category","label":"Data Utilities","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting Started","href":"/projectaria_tools/docs/data_utilities/getting_started","docId":"data_utilities/getting_started"},{"type":"category","label":"Installation Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Download Codebase","href":"/projectaria_tools/docs/data_utilities/installation/download_codebase","docId":"data_utilities/installation/download_codebase"},{"type":"link","label":"Download MPS Sample Data","href":"/projectaria_tools/docs/data_utilities/installation/download_mps_sample_data","docId":"data_utilities/installation/download_mps_sample_data"},{"type":"link","label":"Python Package Installation","href":"/projectaria_tools/docs/data_utilities/installation/installation_python","docId":"data_utilities/installation/installation_python"},{"type":"link","label":"C++ Installation","href":"/projectaria_tools/docs/data_utilities/installation/installation_cpp","docId":"data_utilities/installation/installation_cpp"},{"type":"link","label":"CMake for Your Projects","href":"/projectaria_tools/docs/data_utilities/installation/build_with_cmake","docId":"data_utilities/installation/build_with_cmake"},{"type":"link","label":"Python type annotation","href":"/projectaria_tools/docs/data_utilities/installation/type_hinting","docId":"data_utilities/installation/type_hinting"},{"type":"link","label":"Troubleshooting","href":"/projectaria_tools/docs/data_utilities/installation/troubleshooting","docId":"data_utilities/installation/troubleshooting"}]},{"type":"category","label":"Visualization Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Python Visualization","href":"/projectaria_tools/docs/data_utilities/visualization/visualization_python","docId":"data_utilities/visualization/visualization_python"},{"type":"link","label":"C++ Visualization","href":"/projectaria_tools/docs/data_utilities/visualization/visualization_cpp","docId":"data_utilities/visualization/visualization_cpp"}]},{"type":"category","label":"Core Code Snippets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Data Provider","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/data_provider","docId":"data_utilities/core_code_snippets/data_provider"},{"type":"link","label":"Image","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/image","docId":"data_utilities/core_code_snippets/image"},{"type":"link","label":"Calibration","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/calibration","docId":"data_utilities/core_code_snippets/calibration"},{"type":"link","label":"MPS","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/mps","docId":"data_utilities/core_code_snippets/mps"}]},{"type":"category","label":"Advanced Code Snippets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Plot Sensor Data (Python)","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/plotting_sensor_data","docId":"data_utilities/advanced_code_snippets/plotting_sensor_data"},{"type":"link","label":"Image Utilities (Python and C++)","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/image_utilities","docId":"data_utilities/advanced_code_snippets/image_utilities"},{"type":"link","label":"Export VRS to MP4 (Python)","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/vrs_to_mp4","docId":"data_utilities/advanced_code_snippets/vrs_to_mp4"}]}],"href":"/projectaria_tools/docs/data_utilities/"},{"type":"category","label":"Aria Research Kit","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"About the Aria Research Kit","href":"/projectaria_tools/docs/ARK/about_ARK","docId":"ARK/about_ARK"},{"type":"link","label":"ARK SW Downloads","href":"/projectaria_tools/docs/ARK/ark_downloads","docId":"ARK/ark_downloads"},{"type":"link","label":"Get the Right Size Glasses","href":"/projectaria_tools/docs/ARK/frame_sizing","docId":"ARK/frame_sizing"},{"type":"link","label":"Aria Glasses Quickstart","href":"/projectaria_tools/docs/ARK/ARK_quickstart","docId":"ARK/ARK_quickstart"},{"type":"link","label":"Aria Community (Workplace Group)","href":"/projectaria_tools/docs/ARK/workplacegroup","docId":"ARK/workplacegroup"},{"type":"category","label":"Aria Glasses Manual","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Glasses User Manual","href":"/projectaria_tools/docs/ARK/glasses_manual/glasses_user_manual","docId":"ARK/glasses_manual/glasses_user_manual"},{"type":"link","label":"Fit and Comfort","href":"/projectaria_tools/docs/ARK/glasses_manual/fit_and_comfort","docId":"ARK/glasses_manual/fit_and_comfort"},{"type":"link","label":"Recording Profile Guide","href":"/projectaria_tools/docs/ARK/glasses_manual/profile_guide","docId":"ARK/glasses_manual/profile_guide"}]},{"type":"link","label":"Mobile Companion App","href":"/projectaria_tools/docs/ARK/mobile_companion_app","docId":"ARK/mobile_companion_app"},{"type":"category","label":"Aria Client SDK","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Setup Guide","href":"/projectaria_tools/docs/ARK/sdk/setup","docId":"ARK/sdk/setup"},{"type":"category","label":"Code Samples","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Connection","href":"/projectaria_tools/docs/ARK/sdk/samples/device_connection","docId":"ARK/sdk/samples/device_connection"},{"type":"link","label":"Recording","href":"/projectaria_tools/docs/ARK/sdk/samples/device_recording","docId":"ARK/sdk/samples/device_recording"},{"type":"link","label":"Streaming Subscription","href":"/projectaria_tools/docs/ARK/sdk/samples/streaming_subscribe","docId":"ARK/sdk/samples/streaming_subscribe"},{"type":"link","label":"Streaming and Visualizing All Live Sensor Data","href":"/projectaria_tools/docs/ARK/sdk/samples/device_stream","docId":"ARK/sdk/samples/device_stream"},{"type":"link","label":"Streaming Undistorted RGB Image Using Calibration","href":"/projectaria_tools/docs/ARK/sdk/samples/undistort_rgb_image","docId":"ARK/sdk/samples/undistort_rgb_image"}],"href":"/projectaria_tools/docs/ARK/sdk/samples/"},{"type":"category","label":"Core Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Streaming Internals","href":"/projectaria_tools/docs/ARK/sdk/concepts/streaming_internals","docId":"ARK/sdk/concepts/streaming_internals"},{"type":"link","label":"Access Sensor Profiles","href":"/projectaria_tools/docs/ARK/sdk/concepts/sdk_sensor_profiles","docId":"ARK/sdk/concepts/sdk_sensor_profiles"}]},{"type":"link","label":"API Reference","href":"/projectaria_tools/docs/ARK/sdk/api_reference","docId":"ARK/sdk/api_reference"},{"type":"category","label":"Aria CLI","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Command Reference","href":"/projectaria_tools/docs/ARK/sdk/cli/api_reference","docId":"ARK/sdk/cli/api_reference"}],"href":"/projectaria_tools/docs/ARK/sdk/cli/"},{"type":"link","label":"SDK Troubleshooting & Known Issues","href":"/projectaria_tools/docs/ARK/sdk/sdk_troubleshooting","docId":"ARK/sdk/sdk_troubleshooting"}],"href":"/projectaria_tools/docs/ARK/sdk/"},{"type":"category","label":"Aria Machine Perception Services (MPS)","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Request MPS","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"MPS CLI (Recommended)","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli","docId":"ARK/mps/request_mps/mps_cli"},{"type":"link","label":"MPS CLI Getting Started","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli_getting_started","docId":"ARK/mps/request_mps/mps_cli_getting_started"},{"type":"link","label":"MPS CLI Guide","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli_guide","docId":"ARK/mps/request_mps/mps_cli_guide"},{"type":"link","label":"Desktop App MPS Requests","href":"/projectaria_tools/docs/ARK/mps/request_mps/desktop_mps","docId":"ARK/mps/request_mps/desktop_mps"}]},{"type":"link","label":"Eye Gaze Calibration","href":"/projectaria_tools/docs/ARK/mps/eye_gaze_calibration","docId":"ARK/mps/eye_gaze_calibration"},{"type":"link","label":"MPS Data Processing","href":"/projectaria_tools/docs/ARK/mps/mps_processing","docId":"ARK/mps/mps_processing"}],"href":"/projectaria_tools/docs/ARK/mps/"},{"type":"link","label":"Desktop Companion App","href":"/projectaria_tools/docs/ARK/desktop_companion_app","docId":"ARK/desktop_companion_app"},{"type":"link","label":"ARK Release Notes","href":"/projectaria_tools/docs/ARK/sw_release_notes","docId":"ARK/sw_release_notes"},{"type":"category","label":"ARK Troubleshooting","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Troubleshooting & Known Issues","href":"/projectaria_tools/docs/ARK/troubleshooting/troubleshooting_issues","docId":"ARK/troubleshooting/troubleshooting_issues"},{"type":"link","label":"Desktop App Logs","href":"/projectaria_tools/docs/ARK/troubleshooting/desktop_app_logs","docId":"ARK/troubleshooting/desktop_app_logs"},{"type":"link","label":"Clear Desktop App Cache","href":"/projectaria_tools/docs/ARK/troubleshooting/clear_cache","docId":"ARK/troubleshooting/clear_cache"},{"type":"link","label":"Update Glasses OS","href":"/projectaria_tools/docs/ARK/troubleshooting/update_glasses_os","docId":"ARK/troubleshooting/update_glasses_os"},{"type":"link","label":"Reduce VRS File Size","href":"/projectaria_tools/docs/ARK/troubleshooting/reduce_vrs_file_size","docId":"ARK/troubleshooting/reduce_vrs_file_size"},{"type":"link","label":"Fix USB Driver Issues in Linux","href":"/projectaria_tools/docs/ARK/troubleshooting/linux_usb_driver","docId":"ARK/troubleshooting/linux_usb_driver"},{"type":"link","label":"Get Support","href":"/projectaria_tools/docs/ARK/troubleshooting/get_support","docId":"ARK/troubleshooting/get_support"}]}]},{"type":"category","label":"Open Datasets","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Aria Everyday Activities Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting Started","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_getting_started","docId":"open_datasets/aria_everyday_activities_dataset/aea_getting_started"},{"type":"link","label":"Dataset Download","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_download_dataset","docId":"open_datasets/aria_everyday_activities_dataset/aea_download_dataset"},{"type":"link","label":"Data Format","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_data_format","docId":"open_datasets/aria_everyday_activities_dataset/aea_data_format"},{"type":"link","label":"Visualizer","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_visualizers","docId":"open_datasets/aria_everyday_activities_dataset/aea_visualizers"},{"type":"link","label":"Activities","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_activities","docId":"open_datasets/aria_everyday_activities_dataset/aea_activities"},{"type":"link","label":"Recording Scripts","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_scripts","docId":"open_datasets/aria_everyday_activities_dataset/aea_scripts"}],"href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/"},{"type":"category","label":"Aria Digital Twin Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting Started","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/getting_started","docId":"open_datasets/aria_digital_twin_dataset/getting_started"},{"type":"link","label":"Dataset Download","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download","docId":"open_datasets/aria_digital_twin_dataset/dataset_download"},{"type":"link","label":"Data Format","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_format","docId":"open_datasets/aria_digital_twin_dataset/data_format"},{"type":"link","label":"Data Loader","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_loader","docId":"open_datasets/aria_digital_twin_dataset/data_loader"},{"type":"link","label":"Visualizers","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/visualizers","docId":"open_datasets/aria_digital_twin_dataset/visualizers"},{"type":"link","label":"Advanced Tutorials","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/advanced_tutorials","docId":"open_datasets/aria_digital_twin_dataset/advanced_tutorials"},{"type":"link","label":"ADT Challenges","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/adt_challenges","docId":"open_datasets/aria_digital_twin_dataset/adt_challenges"}],"href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/"},{"type":"category","label":"Aria Synthetic Environments Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting Started","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_getting_started","docId":"open_datasets/aria_synthetic_environments_dataset/ase_getting_started"},{"type":"link","label":"Dataset Download","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_download_dataset","docId":"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset"},{"type":"link","label":"Data Format","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_format","docId":"open_datasets/aria_synthetic_environments_dataset/ase_data_format"},{"type":"link","label":"Data Tools and Visualization","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_tools","docId":"open_datasets/aria_synthetic_environments_dataset/ase_data_tools"},{"type":"link","label":"ASE Challenges","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_challenges","docId":"open_datasets/aria_synthetic_environments_dataset/ase_challenges"}],"href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/"}],"href":"/projectaria_tools/docs/open_datasets/"},{"type":"category","label":"Tech Insights","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Camera Intrinsic Models","href":"/projectaria_tools/docs/tech_insights/camera_intrinsic_models","docId":"tech_insights/camera_intrinsic_models"},{"type":"link","label":"Sensor Measurement Model","href":"/projectaria_tools/docs/tech_insights/sensor_measurement_model","docId":"tech_insights/sensor_measurement_model"},{"type":"link","label":"Camera Photometric and Noise Models","href":"/projectaria_tools/docs/tech_insights/camera_photometric_and_noise_model","docId":"tech_insights/camera_photometric_and_noise_model"},{"type":"link","label":"IMU Noise Model","href":"/projectaria_tools/docs/tech_insights/imu_noise_model","docId":"tech_insights/imu_noise_model"},{"type":"link","label":"Device Timestamping","href":"/projectaria_tools/docs/tech_insights/device_timestamping","docId":"tech_insights/device_timestamping"},{"type":"link","label":"Temporal Alignment of Sensor Data","href":"/projectaria_tools/docs/tech_insights/temporal_alignment_of_sensor_data","docId":"tech_insights/temporal_alignment_of_sensor_data"}],"href":"/projectaria_tools/docs/tech_insights/"},{"type":"link","label":"Attribution and Contributing","href":"/projectaria_tools/docs/attribution_citation/","docId":"attribution_citation/attribution_citation"},{"type":"link","label":"Support","href":"/projectaria_tools/docs/support","docId":"support"}]},"docs":{"ARK/about_ARK":{"id":"ARK/about_ARK","title":"About the Aria Research Kit","description":"The Aria Research Kit (ARK) provides Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to Aria Research Kit intro page at projectaria.com to find out more, or to apply to become a research partner.","sidebar":"tutorialSidebar"},"ARK/ark_downloads":{"id":"ARK/ark_downloads","title":"ARK SW Downloads","description":"The Aria Research Kit (ARK) provides the Aria Mobile Companion app and Desktop Companion app to researchers who use Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/ARK_quickstart":{"id":"ARK/ARK_quickstart","title":"Aria Glasses Quickstart","description":"This page provides a quick overview of what to do once you have received your Project Aria glasses. To find out how to get Aria Glasses, go to projectaria.com.","sidebar":"tutorialSidebar"},"ARK/desktop_companion_app":{"id":"ARK/desktop_companion_app","title":"Desktop Companion App","description":"Overview","sidebar":"tutorialSidebar"},"ARK/frame_sizing":{"id":"ARK/frame_sizing","title":"Get the Right Size Glasses","description":"If you have been approved to become a Project Aria partner and receive the Aria Research Kit (ARK), you\'ll have the option to order Small or Large Aria glasses.","sidebar":"tutorialSidebar"},"ARK/glasses_manual/fit_and_comfort":{"id":"ARK/glasses_manual/fit_and_comfort","title":"Fit and Comfort","description":"Overview","sidebar":"tutorialSidebar"},"ARK/glasses_manual/glasses_user_manual":{"id":"ARK/glasses_manual/glasses_user_manual","title":"Glasses User Manual","description":"The Aria Research Kit (ARK) provides Project Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to Aria Research Kit intro page to find out more or to apply for the ARK.","sidebar":"tutorialSidebar"},"ARK/glasses_manual/profile_guide":{"id":"ARK/glasses_manual/profile_guide","title":"Recording Profile Guide","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mobile_companion_app":{"id":"ARK/mobile_companion_app","title":"Mobile Companion App","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/eye_gaze_calibration":{"id":"ARK/mps/eye_gaze_calibration","title":"Eye Gaze Calibration","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/mps":{"id":"ARK/mps/mps","title":"Machine Perception Services (MPS)","description":"To accelerate research with Project Aria, we provide several Spatial AI machine perception capabilities that help form the foundation for future Contextualized AI applications and analysis of egocentric data. These capabilities are powered by a set of proprietary machine perception algorithms, designed for Project Aria glasses, that provide superior accuracy and robustness on Aria data compared to off-the-shelf open source algorithms.","sidebar":"tutorialSidebar"},"ARK/mps/mps_processing":{"id":"ARK/mps/mps_processing","title":"MPS Data Processing","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/desktop_mps":{"id":"ARK/mps/request_mps/desktop_mps","title":"Desktop App MPS Requests","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli":{"id":"ARK/mps/request_mps/mps_cli","title":"MPS CLI (Recommended)","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli_getting_started":{"id":"ARK/mps/request_mps/mps_cli_getting_started","title":"MPS CLI Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli_guide":{"id":"ARK/mps/request_mps/mps_cli_guide","title":"MPS CLI Guide","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/api_reference":{"id":"ARK/sdk/api_reference","title":"API Reference","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/cli/api_reference":{"id":"ARK/sdk/cli/api_reference","title":"Command Reference","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/cli/cli":{"id":"ARK/sdk/cli/cli","title":"Aria CLI","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/concepts/sdk_sensor_profiles":{"id":"ARK/sdk/concepts/sdk_sensor_profiles","title":"Access Sensor Profiles","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/concepts/streaming_internals":{"id":"ARK/sdk/concepts/streaming_internals","title":"Streaming Internals","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_connection":{"id":"ARK/sdk/samples/device_connection","title":"Connection","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_recording":{"id":"ARK/sdk/samples/device_recording","title":"Recording","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_stream":{"id":"ARK/sdk/samples/device_stream","title":"Streaming and Visualizing All Live Sensor Data","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/samples":{"id":"ARK/sdk/samples/samples","title":"Code Samples","description":"This section provides code samples and walkthroughs for using the Aria Client SDK to interact with the Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/sdk/samples/streaming_subscribe":{"id":"ARK/sdk/samples/streaming_subscribe","title":"Streaming Subscription","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/undistort_rgb_image":{"id":"ARK/sdk/samples/undistort_rgb_image","title":"Streaming Undistorted RGB Image Using Calibration","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/sdk":{"id":"ARK/sdk/sdk","title":"About the SDK","description":"The Project Aria Client SDK provides versatile APIs to help you create your own machine perception Python applications with Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/sdk/sdk_troubleshooting":{"id":"ARK/sdk/sdk_troubleshooting","title":"SDK Troubleshooting & Known Issues","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/setup":{"id":"ARK/sdk/setup","title":"Setup Guide","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sw_release_notes":{"id":"ARK/sw_release_notes","title":"ARK Release Notes","description":"These SW Release notes are for the Aria Research Kit (ARK), and are for Meta SW that supports Academic Research Partners using Project Aria glasses. To find out how to become a research partner, go to projectaria.com.","sidebar":"tutorialSidebar"},"ARK/troubleshooting/clear_cache":{"id":"ARK/troubleshooting/clear_cache","title":"Clear Desktop App Cache","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/desktop_app_logs":{"id":"ARK/troubleshooting/desktop_app_logs","title":"Desktop App Logs","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/get_support":{"id":"ARK/troubleshooting/get_support","title":"Get Support","description":"If you need further support, have feedback or feature requests we encourage you to:","sidebar":"tutorialSidebar"},"ARK/troubleshooting/linux_usb_driver":{"id":"ARK/troubleshooting/linux_usb_driver","title":"Fix USB Driver Issues in Linux","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/reduce_vrs_file_size":{"id":"ARK/troubleshooting/reduce_vrs_file_size","title":"Reduce VRS File Size","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/troubleshooting_issues":{"id":"ARK/troubleshooting/troubleshooting_issues","title":"Troubleshooting & Known Issues","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/update_glasses_os":{"id":"ARK/troubleshooting/update_glasses_os","title":"Update Glasses OS","description":"Overview","sidebar":"tutorialSidebar"},"ARK/workplacegroup":{"id":"ARK/workplacegroup","title":"Aria Community (Workplace Group)","description":"Overview","sidebar":"tutorialSidebar"},"attribution_citation/attribution_citation":{"id":"attribution_citation/attribution_citation","title":"Attribution and Contributing","description":"Citation","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs":{"id":"data_formats/aria_vrs/aria_vrs","title":"Aria VRS","description":"Overview","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs_format":{"id":"data_formats/aria_vrs/aria_vrs_format","title":"Format","description":"This page provides information about how Aria data streams are identified in VRS, Aria sensor data configuration, followed by useful VRS tools for common use cases.","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/timestamps_in_aria_vrs":{"id":"data_formats/aria_vrs/timestamps_in_aria_vrs","title":"Timestamp Definitions","description":"This page provides information about how Project Aria timestamp data is formatted in VRS.","sidebar":"tutorialSidebar"},"data_formats/coordinate_convention/2d_image_coordinate_system_convention":{"id":"data_formats/coordinate_convention/2d_image_coordinate_system_convention","title":"2D Image Coordinate System Conventions","description":"For any provided camera intrinsic calibration value we use the convention that the color value of a pixel with integer coordinates $(u,v)$ is the average color of the square spanning from $(u-0.5,v-0.5)$ to $(u+0.5,v+0.5)$ in continuous coordinates.","sidebar":"tutorialSidebar"},"data_formats/coordinate_convention/3d_coordinate_frame_convention":{"id":"data_formats/coordinate_convention/3d_coordinate_frame_convention","title":"3D Coordinate Frame Conventions","description":"This page provides an overview of 3D Coordinate Frame Conventions used for Project Aria glasses, covering:","sidebar":"tutorialSidebar"},"data_formats/data_formats":{"id":"data_formats/data_formats","title":"Data Formats","description":"In this section, we describe:","sidebar":"tutorialSidebar"},"data_formats/mps/mps_eye_gaze":{"id":"data_formats/mps/mps_eye_gaze","title":"Eye Gaze","description":"Eye Gaze Data Format","sidebar":"tutorialSidebar"},"data_formats/mps/mps_summary":{"id":"data_formats/mps/mps_summary","title":"Basics","description":"This page provides an overview of how Project Aria Machine Perception Services (MPS) output files are formatted.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_calibration":{"id":"data_formats/mps/slam/mps_calibration","title":"Calibration Data","description":"Online calibration is generated as part of SLAM (Location in the Desktop Companion app) MPS requests.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_multi_slam":{"id":"data_formats/mps/slam/mps_multi_slam","title":"Multi-SLAM","description":"Multi-SLAM is a Project Aria Machine Perception Service (MPS) that can be requested on two or more recordings. It creates SLAM MPS outputs in a shared co-ordinate frame.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_pointcloud":{"id":"data_formats/mps/slam/mps_pointcloud","title":"Semi-Dense Point Cloud","description":"Semi-Dense Point Cloud is a Project Aria Machine Perception Service (MPS) that is generated as part of SLAM (location with point cloud in the Desktop Companion app) MPS requests.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_trajectory":{"id":"data_formats/mps/slam/mps_trajectory","title":"Trajectory","description":"6DoF trajectory data is generated as part of SLAM (location in the Desktop Companion app) Machine Perception Services (MPS) requests:","sidebar":"tutorialSidebar"},"data_formats/mps/slam/slam":{"id":"data_formats/mps/slam/slam","title":"SLAM MPS Outputs","description":"This section covers MPS outputs relating to SLAM.","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/image_utilities":{"id":"data_utilities/advanced_code_snippets/image_utilities","title":"Image Utilities (Python and C++)","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/plotting_sensor_data":{"id":"data_utilities/advanced_code_snippets/plotting_sensor_data","title":"Plot Sensor Data (Python)","description":"This tutorial shows how to plot Project Aria sensor data using Python. This example covers how to:","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/vrs_to_mp4":{"id":"data_utilities/advanced_code_snippets/vrs_to_mp4","title":"Export VRS to MP4 (Python)","description":"The vrstomp4 script enables you to create an MP4 video from a Project Aria VRS recording.","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/calibration":{"id":"data_utilities/core_code_snippets/calibration","title":"Calibration","description":"In this section, we introduce the Python/C++ API for accessing calibration data from Project Aria VRS files (projectariatools/main/core/calibration).","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/data_provider":{"id":"data_utilities/core_code_snippets/data_provider","title":"Data Provider","description":"In this section, we introduce the Python/C++ API to access sensor data in Project Aria VRS files (projectariatools/main/core/dataprovider).","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/image":{"id":"data_utilities/core_code_snippets/image","title":"Image","description":"In this section, we introduce the Python/C++ API to access and manipulate Project Aria images (projectariatools/main/core/image). Raw Aria data is stored in VRS files.","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/mps":{"id":"data_utilities/core_code_snippets/mps","title":"MPS","description":"Project Aria Machine Perception Services (MPS) enables Aria users with access to the Aria Research Kit to request derived data on Aria VRS files.","sidebar":"tutorialSidebar"},"data_utilities/data_utilities":{"id":"data_utilities/data_utilities","title":"Overview","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/getting_started":{"id":"data_utilities/getting_started","title":"Getting Started","description":"In this guide, we introduce how to install the projectaria_tools Python package and provide tutorials to go through the APIs to access and visualize Aria data.","sidebar":"tutorialSidebar"},"data_utilities/installation/build_with_cmake":{"id":"data_utilities/installation/build_with_cmake","title":"CMake for Your Projects","description":"To use projectaria_tools for your own projects with CMake, we recommend adding it as a submodule in your project.","sidebar":"tutorialSidebar"},"data_utilities/installation/download_codebase":{"id":"data_utilities/installation/download_codebase","title":"Download Codebase","description":"Supported Platforms","sidebar":"tutorialSidebar"},"data_utilities/installation/download_mps_sample_data":{"id":"data_utilities/installation/download_mps_sample_data","title":"Download MPS Sample Data","description":"This sample (hosted at projectaria.com) contains a raw VRS file and all the corresponding MPS outputs.","sidebar":"tutorialSidebar"},"data_utilities/installation/installation_cpp":{"id":"data_utilities/installation/installation_cpp","title":"C++ Installation","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/installation/installation_python":{"id":"data_utilities/installation/installation_python","title":"Python Package Installation","description":"This page provides information about how to install the Python utilities using a virtual environment or from source. We recommend that only advanced users install from source.","sidebar":"tutorialSidebar"},"data_utilities/installation/troubleshooting":{"id":"data_utilities/installation/troubleshooting","title":"Troubleshooting","description":"Jupyter notebook issues","sidebar":"tutorialSidebar"},"data_utilities/installation/type_hinting":{"id":"data_utilities/installation/type_hinting","title":"Python type annotation","description":"This page provides information about how to use the python type hinting from stub files (*.pyi).","sidebar":"tutorialSidebar"},"data_utilities/visualization/visualization_cpp":{"id":"data_utilities/visualization/visualization_cpp","title":"C++ Visualization","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/visualization/visualization_python":{"id":"data_utilities/visualization/visualization_python","title":"Python Visualization","description":"Overview","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Project Aria Tools","description":"Project Aria Tools provides open tooling to support researchers expand the horizons of Augmented Reality, Machine Perception and Artificial Intelligence.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/adt_challenges":{"id":"open_datasets/aria_digital_twin_dataset/adt_challenges","title":"ADT Challenges","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/advanced_tutorials":{"id":"open_datasets/aria_digital_twin_dataset/advanced_tutorials","title":"Advanced Tutorials","description":"Multi-person Synchronization","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/aria_digital_twin_dataset":{"id":"open_datasets/aria_digital_twin_dataset/aria_digital_twin_dataset","title":"Overview","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/data_format":{"id":"open_datasets/aria_digital_twin_dataset/data_format","title":"Data Format","description":"The Aria Digital Twin Dataset (ADT) provides real world and synthetic raw Project Aria data, derived data generated by ADT Ground Truth data processing services as well as derived data generated by Project Aria\'s Machine Perception Services (MPS).","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/data_loader":{"id":"open_datasets/aria_digital_twin_dataset/data_loader","title":"Data Loader","description":"Data loading is broken down into two main loaders: AriaDigitalTwinDataPathsProvider, AriaDigitalTwinDataProvider.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/dataset_download":{"id":"open_datasets/aria_digital_twin_dataset/dataset_download","title":"Dataset Download","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/getting_started":{"id":"open_datasets/aria_digital_twin_dataset/getting_started","title":"Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/visualizers":{"id":"open_datasets/aria_digital_twin_dataset/visualizers","title":"Visualizers","description":"To help you visualize and debug your algorithms when using the Aria Digital Twin (ADT) dataset, we\u2019ve provided the following visualizers:","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_activities":{"id":"open_datasets/aria_everyday_activities_dataset/aea_activities","title":"Activities","description":"When creating recordings for one to two Project Aria glasses wearers for the Aria Everyday Activities (AEA) dataset, we created scripts to represent all day long activities with always on sensing. Each script contained multiple scenarios that told a story about people going through their day. The scripts provided general guidance for an improvised scenario. Actors did not have specific lines to learn, instead they followed prompts and went with what felt most natural to to them.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_data_format":{"id":"open_datasets/aria_everyday_activities_dataset/aea_data_format","title":"Data Format","description":"The Aria Everyday Activities dataset contains multiple activity sequences for one to two Project Aria glasses users. We created recordings using scripts to represent all day activities with always on sensing.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_download_dataset":{"id":"open_datasets/aria_everyday_activities_dataset/aea_download_dataset","title":"Dataset Download","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_getting_started":{"id":"open_datasets/aria_everyday_activities_dataset/aea_getting_started","title":"Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_scripts":{"id":"open_datasets/aria_everyday_activities_dataset/aea_scripts","title":"Recording Scripts","description":"The following scripts were used by actors to collect data for the Aria Everyday Activities (AEA) dataset.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_visualizers":{"id":"open_datasets/aria_everyday_activities_dataset/aea_visualizers","title":"Visualizer","description":"To help you visualize and debug your algorithms when using the Aria Everyday Activities (AEA) dataset, we\u2019ve provided a Python based visualizer that can work with time synchronized data from multiple Project Aria glasses in a shared world location.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aria_everyday_activities_dataset":{"id":"open_datasets/aria_everyday_activities_dataset/aria_everyday_activities_dataset","title":"Aria Everyday Activities Dataset","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/aria_synthetic_environments_dataset":{"id":"open_datasets/aria_synthetic_environments_dataset/aria_synthetic_environments_dataset","title":"Aria Synthetic Environments Dataset","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_challenges":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_challenges","title":"ASE Challenges","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_data_format":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_data_format","title":"Data Format","description":"This page provides an overview of Aria Synthetic Environments (ASE) data formats and organization.","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_data_tools":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_data_tools","title":"Data Tools and Visualization","description":"We provide different functions and code snippets in Python to load Aria Synthetic Environments (ASE) data from a sequence and associate/interpret them with each other. The contents of each scene/sequence are detailed in Data Format.","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset","title":"Dataset Download","description":"By downloading the datasets you agree that you have read and accepted the terms of","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_getting_started":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_getting_started","title":"Getting Started","description":"This section will cover everything you need to know to get up and running using Aria Synthetic Environments (ASE) visualizers and data loaders. ASE tooling contains:","sidebar":"tutorialSidebar"},"open_datasets/open_datasets":{"id":"open_datasets/open_datasets","title":"Open Datasets","description":"This section provides information about how to use Project Aria\'s open data.","sidebar":"tutorialSidebar"},"support":{"id":"support","title":"Support","description":"Overview","sidebar":"tutorialSidebar"},"tech_insights/camera_intrinsic_models":{"id":"tech_insights/camera_intrinsic_models","title":"Camera Intrinsic Models","description":"This page provides an overview of the intrinsic models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses.","sidebar":"tutorialSidebar"},"tech_insights/camera_photometric_and_noise_model":{"id":"tech_insights/camera_photometric_and_noise_model","title":"Camera Photometric and Noise Models","description":"This page provides an overview of the Photometric and Noise models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses.","sidebar":"tutorialSidebar"},"tech_insights/device_timestamping":{"id":"tech_insights/device_timestamping","title":"Device Timestamping","description":"This page provides an overview of Project Aria devices are configured to create time aligned VRS recordings. Go to Timestamps in Aria VRS for how Aria data is formatted. Go to Temporal Alignment of Aria Sensor Data for Project Aria data is temporally aligned and provides information about how to finely align IMU, barometer and magnetometer data.","sidebar":"tutorialSidebar"},"tech_insights/imu_noise_model":{"id":"tech_insights/imu_noise_model","title":"IMU Noise Model","description":"In our visual-inertial fusion algorithm, we model, as traditionally done, the stochastic part of the IMU error as including three components:","sidebar":"tutorialSidebar"},"tech_insights/sensor_measurement_model":{"id":"tech_insights/sensor_measurement_model","title":"Sensor Measurement Model","description":"This page provides an overview of how Project Aria device sensor measurements are modeled for IMU, magnetometer, barometer and audio.","sidebar":"tutorialSidebar"},"tech_insights/tech_insights":{"id":"tech_insights/tech_insights","title":"Tech Insights","description":"Technical deeper dives on domain-specific topics. You don\'t need to read this section to use Project Aria data or glasses, but you may find it interesting to understand how Aria glasses work.","sidebar":"tutorialSidebar"},"tech_insights/temporal_alignment_of_sensor_data":{"id":"tech_insights/temporal_alignment_of_sensor_data","title":"Temporal Alignment of Sensor Data","description":"This page provides an overview of how Project Aria data is temporally aligned and provides information about how to finely align IMU, barometer and magnetometer data.","sidebar":"tutorialSidebar"},"tech_spec/device_calibration":{"id":"tech_spec/device_calibration","title":"Device Calibration","description":"Most sensors in Project Aria glasses are calibrated extrinsically and intrinsically, to rectify from sensor measurements to real quantities in the physical world. Extrinsic calibrations model the 6-DoF pose among the sensors, while intrinsic calibrations model how sensor measurements maps to physical or geometrical quantities in the physical world. We also provide the extrinsic pose for the sensors in the CAD model to indicate where sensors are designed to be.","sidebar":"tutorialSidebar"},"tech_spec/hardware_spec":{"id":"tech_spec/hardware_spec","title":"Hardware Specifications","description":"Project Aria glasses have five cameras (two Mono Scene, one RGB, and two Eye Tracking cameras) as well as non-visual sensors (two IMUs, magnetometer, barometer, GPS, Wi-Fi beacon, Bluetooth beacon and Microphones). Mono Scene Cameras are often used to support SLAM algorithms, but they can have other applications.","sidebar":"tutorialSidebar"},"tech_spec/recording_profiles":{"id":"tech_spec/recording_profiles","title":"Recording Profiles","description":"Project Aria glasses have multiple recording profiles that enable users to choose what sensors to record with and what settings to use.  Aria glasses currently support 17 different recording profiles, which vary by:","sidebar":"tutorialSidebar"},"tech_spec/tech_spec":{"id":"tech_spec/tech_spec","title":"Technical Specifications","description":"The Technical Specifications section provides information about Project Aria glasses hardware, the different configurations Aria glasses can use when recording, and how Aria glasses are calibrated.","sidebar":"tutorialSidebar"}}}')}}]);