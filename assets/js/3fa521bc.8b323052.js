"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3036],{15680:(e,t,o)=>{o.r(t),o.d(t,{MDXContext:()=>l,MDXProvider:()=>p,mdx:()=>b,useMDXComponents:()=>m,withMDXComponents:()=>d});var r=o(96540);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function a(){return a=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var o=arguments[t];for(var r in o)Object.prototype.hasOwnProperty.call(o,r)&&(e[r]=o[r])}return e},a.apply(this,arguments)}function i(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,r)}return o}function s(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?i(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function c(e,t){if(null==e)return{};var o,r,n=function(e,t){if(null==e)return{};var o,r,n={},a=Object.keys(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var l=r.createContext({}),d=function(e){return function(t){var o=m(t.components);return r.createElement(e,a({},t,{components:o}))}},m=function(e){var t=r.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):s(s({},t),e)),o},p=function(e){var t=m(e.components);return r.createElement(l.Provider,{value:t},e.children)},h="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},f=r.forwardRef((function(e,t){var o=e.components,n=e.mdxType,a=e.originalType,i=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),d=m(o),p=n,h=d["".concat(i,".").concat(p)]||d[p]||u[p]||a;return o?r.createElement(h,s(s({ref:t},l),{},{components:o})):r.createElement(h,s({ref:t},l))}));function b(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var a=o.length,i=new Array(a);i[0]=f;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[h]="string"==typeof e?e:n,i[1]=s;for(var l=2;l<a;l++)i[l]=o[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,o)}f.displayName="MDXCreateElement"},50975:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>l});var r=o(58168),n=(o(96540),o(15680));const a={sidebar_position:60,title:"Camera Photometric and Noise Models"},i="Camera Photometric and Noise Models for Project Aria Glasses",s={unversionedId:"tech_insights/camera_photometric_and_noise_model",id:"tech_insights/camera_photometric_and_noise_model",title:"Camera Photometric and Noise Models",description:"This page provides an overview of the Photometric and Noise models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses.",source:"@site/docs/tech_insights/camera_photometric_and_noise_model.mdx",sourceDirName:"tech_insights",slug:"/tech_insights/camera_photometric_and_noise_model",permalink:"/projectaria_tools/docs/tech_insights/camera_photometric_and_noise_model",draft:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/tech_insights/camera_photometric_and_noise_model.mdx",tags:[],version:"current",sidebarPosition:60,frontMatter:{sidebar_position:60,title:"Camera Photometric and Noise Models"},sidebar:"tutorialSidebar",previous:{title:"Sensor Measurement Model",permalink:"/projectaria_tools/docs/tech_insights/sensor_measurement_model"},next:{title:"IMU Noise Model",permalink:"/projectaria_tools/docs/tech_insights/imu_noise_model"}},c={},l=[{value:"Photometric Models",id:"photometric-models",level:2},{value:"Noise Models",id:"noise-models",level:2}],d={toc:l},m="wrapper";function p(e){let{components:t,...o}=e;return(0,n.mdx)(m,(0,r.A)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,n.mdx)("h1",{id:"camera-photometric-and-noise-models-for-project-aria-glasses"},"Camera Photometric and Noise Models for Project Aria Glasses"),(0,n.mdx)("p",null,"This page provides an overview of the Photometric and Noise models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses."),(0,n.mdx)("h2",{id:"photometric-models"},"Photometric Models"),(0,n.mdx)("p",null,"In their working distance range, Aria camera lenses are well-focused, i.e. their point spread function is at sub-pixel level. Thus, we can establish a simplified photometric model where each camera pixel collects the photon emitted from a tiny surface area around a corresponding world point."),(0,n.mdx)("p",null,"The irradiance of each pixel is attenuated by vignetting. The vignetting of Aria cameras are dominated by two factors (1) cos^4 fall-off (2) mechanical cropping of the lens barrel.\nPoints that falls out of the camera's FOV are not visible, and cannot be applied by the above intrinsic model."),(0,n.mdx)("p",null,"Then each pixel takes the time integral of the irradiance, as the sensors collect the arriving photon over the exposure time. The pixel intensity of a non-linear function of the amount of received photons as the ADC transform is non-linear and saturated."),(0,n.mdx)("h2",{id:"noise-models"},"Noise Models"),(0,n.mdx)("p",null,"The two sources of noise dominating Aria camera sensors are:"),(0,n.mdx)("ul",null,(0,n.mdx)("li",{parentName:"ul"},"Shot noise, which accounts for the noise generated due to arrival of photons. Shot noise follows the Poisson distribution."),(0,n.mdx)("li",{parentName:"ul"},"Read noise, which accounts for the noise generated due to ADC conversion, etc. Read noise can be modeled by a zero-mean Gaussian random variable.")))}p.isMDXComponent=!0}}]);